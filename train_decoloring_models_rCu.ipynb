{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run mi_lsd_header_and_preprocessing_functions.py\n",
    "## set path to data_lsd_trip\n",
    "## HERE\n",
    "drive = \"/SETDRIVEPATH/data_lsd_trip/\"\n",
    "\n",
    "def train_rf_model(y, X, method, o_path, set_name, n_estimators = 100, max_depth = 30, criterion = \"mse\"):\n",
    "    t = time.time()\n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators, \n",
    "                               max_depth=max_depth, n_jobs=15, \n",
    "                               random_state=None,\n",
    "                               criterion=criterion)\n",
    "    rf.fit(X, y)\n",
    "    savepath = o_path+'rf_'+method+'_'+set_name+'_n'+str(n_estimators)+'_d'+str(max_depth)+'_c.'+criteron\n",
    "    pickle.dump(rf, open(savepath, 'wb') )\n",
    "    print(\"saved model to\", savepath)\n",
    "    print(\"elapsed time:\", time.time()-t,\"s\")\n",
    "    del(rf)\n",
    "\n",
    "def train_nn_model(y, X, method, o_path, set_name, verbose = False, \n",
    "                   batch_size = 10000, epochs = 100, learning_rate=0.01, dropout_p=0.0):\n",
    "    t = time.time()\n",
    "    torch.manual_seed(1)\n",
    "    cuda = torch.device(\"cuda:0\")\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    x, y = (Variable(torch.from_numpy(X[:,:].astype(np.float32)).cuda()), \n",
    "            Variable(torch.unsqueeze(torch.from_numpy(y[:].astype(np.float32)).cuda(), dim=1))\n",
    "            )\n",
    "    x = x.to(cuda)\n",
    "    y = y.to(cuda)\n",
    "\n",
    "    n_input = X.shape[1]\n",
    "\n",
    "    net = torch.nn.Sequential(\n",
    "        torch.nn.Linear(n_input, 2*n_input),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(2*n_input, 2*n_input),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Dropout(p=dropout_p),\n",
    "        torch.nn.Linear(2*n_input, 2*n_input),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Dropout(p=dropout_p),\n",
    "        torch.nn.Linear(2*n_input, 2*n_input),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Dropout(p=dropout_p),\n",
    "        torch.nn.Linear(2*n_input, 1)\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    loss_func = torch.nn.L1Loss()\n",
    "    torch_dataset = Data.TensorDataset(x, y)\n",
    "\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True)\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        for step, (batch_x, batch_y) in enumerate(loader): # for each training step\n",
    "            lr = learning_rate * (0.9 ** (epoch/2))\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            \n",
    "            b_x = Variable(batch_x)\n",
    "            b_y = Variable(batch_y)\n",
    "            prediction = net(b_x)     # predict based on x\n",
    "\n",
    "            loss = loss_func(prediction, b_y)     # (1. nn output, 2. target)\n",
    "            losses.append(loss)\n",
    "            optimizer.zero_grad()   # clear gradients for next train\n",
    "            loss.backward()         # backpropagation, compute gradients\n",
    "            optimizer.step()        # apply gradients\n",
    "\n",
    "        if epoch%10 == 0:\n",
    "            print(\"Epoch\", epoch,\"/\", epochs)\n",
    "    net_cpu = net.cpu()\n",
    "    del(net)\n",
    "    savepath = o_path+'nn_'+method+'_'+set_name+'_b'+str(batch_size)+'_e'+str(epochs)+'_l'+str(learning_rate)+'_d'+str(dropout_p)\n",
    "    torch.save(net_cpu, savepath)\n",
    "    print(\"saved model to\", savepath)\n",
    "    print(\"elapsed time:\", time.time()-t,\"s\")\n",
    "    \n",
    "    if verbose:\n",
    "        fig, ax = plt.subplots(figsize=(6,6))\n",
    "        plt.cla()\n",
    "        ax.set_title('Regression Analysis', fontsize=18)\n",
    "        ax.set_xlabel('gt', fontsize=14)\n",
    "        ax.set_ylabel('est', fontsize=14)\n",
    "        ax.set_xlim(-0.1, 1.1)\n",
    "        ax.set_ylim(-0.1, 1.1)\n",
    "        ax.scatter(y.data.cpu().numpy(), y.data.cpu().numpy(), color = \"blue\", alpha=0.1)\n",
    "\n",
    "        prediction = net_cpu(x.data.cpu())\n",
    "        ax.scatter(y.data.cpu().numpy(), prediction.data.cpu().numpy(), color='green', alpha=0.005)\n",
    "        plt.savefig(o_path+'nn_'+method+'_'+set_name+'_end.png')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.plot(np.log(losses))\n",
    "        plt.savefig(o_path+'nn_'+method+'_'+set_name+'_losses.png')\n",
    "        plt.show()\n",
    "\n",
    "        foo = np.abs(y.data.cpu().numpy()-prediction.data.cpu().numpy())\n",
    "        f = plt.hist(foo, bins=np.linspace(0,0.4,100), alpha=0.5)\n",
    "        plt.show()\n",
    "        print(\"mean abs err on train set:\", np.mean(foo))\n",
    "    del(net_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## main results\n",
    "\n",
    "set_name = \"SET03_TRAIN\"\n",
    "i_path = drive+\"data_in_silico/MI-LSD_\"\n",
    "o_path = drive+\"trained_models/0-15-unsorted-augmented/\"\n",
    "\n",
    "method=\"lsd\"\n",
    "y, X, S = preprocess_np_for_lsd(i_path+set_name, start_wl_id=0, stop_wl_id=16)\n",
    "train_rf_model(y, X, method, o_path, set_name, n_estimators = 100, max_depth = 30)\n",
    "train_nn_model(y, X, method, o_path, set_name, epochs=100, verbose = True, learning_rate=0.01, dropout_p=0.0)\n",
    "train_nn_model(y, X, method, o_path, set_name, epochs=100, verbose = True, learning_rate=0.01, dropout_p=0.2)\n",
    "\n",
    "method=\"mi-lsd\"\n",
    "y, X = preprocess_np_for_milsd(i_path+set_name, start_wl_id=0, stop_wl_id=16, sort=False, data_augment=True)\n",
    "train_rf_model(y, X, method, o_path, set_name, n_estimators = 100, max_depth = 30)\n",
    "train_nn_model(y, X, method, o_path, set_name, epochs=100, verbose = True, learning_rate=0.01, dropout_p=0.0)\n",
    "train_nn_model(y, X, method, o_path, set_name, epochs=100, verbose = True, learning_rate=0.01, dropout_p=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with only 13 walvelengths\n",
    "set_name = \"SET03_TRAIN\"\n",
    "i_path = drive+\"data_in_silico/MI-LSD_\"\n",
    "o_path = drive+\"trained_models/0-12-unsorted-augmented/\"\n",
    "method=\"lsd\"\n",
    "y, X, S = preprocess_np_for_lsd(i_path+set_name, start_wl_id=0, stop_wl_id=13)\n",
    "train_rf_model(y, X, method, o_path, set_name, n_estimators = 100, max_depth = 30)\n",
    "train_nn_model(y, X, method, o_path, set_name, epochs=100, verbose = True, learning_rate=0.01, dropout_p=0.0)\n",
    "\n",
    "method=\"mi-lsd\"\n",
    "y, X = preprocess_np_for_milsd(i_path+set_name, start_wl_id=0, stop_wl_id=13, sort=False, data_augment=True)\n",
    "train_rf_model(y, X, method, o_path, set_name, n_estimators = 100, max_depth = 30)\n",
    "train_nn_model(y, X, method, o_path, set_name, epochs=100, verbose = True, learning_rate=0.01, dropout_p=0.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
